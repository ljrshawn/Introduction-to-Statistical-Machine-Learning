{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d383327",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Assignment 2: Support Vector Machines\n",
    "\n",
    "Jingran Lyu a1832252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49d23183",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cvxopt import matrix as cvxopt_matrix\n",
    "from cvxopt import solvers as cvxopt_solvers\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f4e9ca4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Data set\n",
    "train = pd.read_csv('/Users/shawnl/Downloads/train.csv', header=None)\n",
    "test = pd.read_csv('/Users/shawnl/Downloads/test.csv', header=None)\n",
    "# train.head()\n",
    "# test.head()\n",
    "x_train, x_valid = train.iloc[:4000, 1:], train.iloc[4000:, 1:]\n",
    "y_train, y_valid = train.iloc[:4000, 0], train.iloc[4000:, 0]\n",
    "x_test, y_test = test.iloc[:, 1:], test.iloc[:, 0]\n",
    "y_train, y_valid, y_test = np.where(y_train == 0, -1, y_train), \\\n",
    "                            np.where(y_valid == 0, -1, y_valid), \\\n",
    "                            np.where(y_test == 0, -1, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de1e3f5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The primal form of soft-margin Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0732f7a9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Primal form of soft-margin SVM trainning\n",
    "def svm_train_primal (data_train ,label_train ,regularisation_para_C):\n",
    "    m, n = data_train.shape\n",
    "    p_w, p_b, p_xi = np.asarray(np.diag(np.ones(n))), np.zeros([1,1]), np.zeros([m, n])\n",
    "    p_w_s, p_b_s, p_xi_s= np.zeros([1, n]), np.zeros([1, m]), np.zeros((m, m))\n",
    "\n",
    "    P = cvxopt_matrix(np.concatenate((np.concatenate((p_w, p_w_s.T, p_xi.T), axis = 1), \n",
    "                       np.concatenate((p_xi, p_b_s.T, p_xi_s), axis = 1),\n",
    "                       np.concatenate((p_w_s, p_b, p_b_s), axis = 1)), axis = 0))\n",
    "    \n",
    "    q = cvxopt_matrix(np.concatenate((p_w_s, p_b, np.ones([1, m]) * (regularisation_para_C / m)), axis = 1).T)\n",
    "    \n",
    "    g_1 = np.dot(np.diag(label_train), data_train) * (-1)\n",
    "    g_2 = (np.matrix(label_train) * (-1)).T\n",
    "    g_3 = np.diag(np.ones([m]) * (-1))\n",
    "    G = cvxopt_matrix(np.concatenate((np.concatenate((g_1, g_2, g_3), axis = 1),\n",
    "                      np.concatenate((np.zeros([m, n]), np.zeros([m, 1]), g_3), axis = 1)), axis = 0))\n",
    "    \n",
    "    h = cvxopt_matrix(np.concatenate((np.ones([m, 1]) * -1, np.zeros([m, 1])), axis = 0))\n",
    "    primal_model = np.array(cvxopt_solvers.qp(P,q,G,h)['x']).flatten()\n",
    "    return primal_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2354eaf9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  7.1592e+00  6.0250e+02  4e+04  3e+00  2e+04\n",
      " 1:  2.1840e+02 -8.6176e+02  1e+03  7e-02  4e+02\n",
      " 2:  1.3725e+02 -9.0183e+01  2e+02  1e-02  5e+01\n",
      " 3:  4.8478e+01 -1.5479e+01  6e+01  3e-03  1e+01\n",
      " 4:  2.4467e+01 -2.7209e+00  3e+01  1e-03  6e+00\n",
      " 5:  1.1255e+01  3.8462e+00  7e+00  3e-04  1e+00\n",
      " 6:  7.9712e+00  5.4852e+00  2e+00  6e-05  3e-01\n",
      " 7:  6.9506e+00  5.9990e+00  1e+00  2e-05  9e-02\n",
      " 8:  6.5698e+00  6.1903e+00  4e-01  2e-06  1e-02\n",
      " 9:  6.4094e+00  6.2999e+00  1e-01  5e-07  3e-03\n",
      "10:  6.3622e+00  6.3341e+00  3e-02  9e-08  5e-04\n",
      "11:  6.3477e+00  6.3454e+00  2e-03  4e-09  2e-05\n",
      "12:  6.3465e+00  6.3464e+00  2e-04  1e-10  7e-07\n",
      "13:  6.3464e+00  6.3464e+00  4e-06  3e-12  1e-08\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "svm_model_primal = svm_train_primal(x_train, y_train, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e50466e1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Primal form testing\n",
    "def svm_predict_primal (data_test , label_test , model):\n",
    "    m, n = data_test.shape\n",
    "    accuracy = accuracy_score(label_test, np.sign(np.dot(data_test, model[:n]) + model[n]))\n",
    "    return accuracy\n",
    "# print(svm_predict_primal(x_test, y_test, svm_model_primal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcf91c02",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.14513522739480422 1.7798092086721722\n"
     ]
    }
   ],
   "source": [
    "# Quick check w and b\n",
    "def quick_check_primal(data_train, label_train, model):\n",
    "    w_primal, b_primal = np.sum(model[:data_train.shape[1]]), model[data_train.shape[1]]\n",
    "    print(w_primal , b_primal)\n",
    "    xi = model[data_train.shape[1]+1:]\n",
    "    support_vectors = np.where(xi < 1e-6, True, False)\n",
    "    xi = xi[support_vectors]\n",
    "    # print(xi.shape)\n",
    "quick_check_primal(x_train, y_train, svm_model_primal)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dual form of soft-margin Linear Support Vector Machine"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dab33e2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Dual form of soft-margin SVM training\n",
    "def svm_train_dual (data_train ,label_train ,regularisation_para_C):\n",
    "    m, n = data_train.shape\n",
    "    p_y = np.diag(label_train).T\n",
    "    p_yx = np.dot(p_y, data_train)\n",
    "    P = cvxopt_matrix(np.dot(p_yx, p_yx.T))\n",
    "    q = cvxopt_matrix((np.ones([1, m]) * -1).T)\n",
    "    G = cvxopt_matrix(np.concatenate((np.diag(np.ones([m])), np.diag(np.ones([m])) * -1), axis = 0))\n",
    "    h = cvxopt_matrix(np.concatenate((np.ones([m, 1]) * (regularisation_para_C / m), np.zeros([m, 1])), axis = 0))\n",
    "    A = cvxopt_matrix(np.matrix(y_train))\n",
    "    b = cvxopt_matrix(np.zeros([1]))\n",
    "    dual_model = np.array(cvxopt_solvers.qp(P, q, G, h, A, b)[\"x\"]).flatten()\n",
    "    return dual_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ea1ce2f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.8416e+02 -2.2800e+02  4e+04  1e+02  5e-13\n",
      " 1: -2.2204e+01 -2.2367e+02  1e+03  3e+00  5e-13\n",
      " 2: -1.2704e+01 -1.3798e+02  2e+02  4e-01  7e-14\n",
      " 3: -8.2452e+00 -4.8671e+01  6e+01  1e-01  3e-14\n",
      " 4: -6.5928e+00 -2.4543e+01  3e+01  4e-02  2e-14\n",
      " 5: -5.8533e+00 -1.1273e+01  7e+00  1e-02  2e-14\n",
      " 6: -5.9382e+00 -7.9755e+00  2e+00  2e-03  2e-14\n",
      " 7: -6.1146e+00 -6.9517e+00  1e+00  7e-04  2e-14\n",
      " 8: -6.2067e+00 -6.5700e+00  4e-01  1e-04  2e-14\n",
      " 9: -6.3032e+00 -6.4094e+00  1e-01  2e-05  2e-14\n",
      "10: -6.3347e+00 -6.3622e+00  3e-02  4e-06  2e-14\n",
      "11: -6.3454e+00 -6.3477e+00  2e-03  1e-07  2e-14\n",
      "12: -6.3464e+00 -6.3465e+00  2e-04  5e-09  2e-14\n",
      "13: -6.3464e+00 -6.3464e+00  4e-06  1e-10  2e-14\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "svm_model_dual = svm_train_dual(x_train, y_train, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Dual form testing\n",
    "def svm_predict_dual (data_test , label_test , model):\n",
    "    dual_model = obtain_primal_from_dual(x_train, y_train, model)\n",
    "    accuracy = accuracy_score(label_test, np.sign(np.dot(data_test, dual_model[:-1]) + dual_model[-1]))\n",
    "    return accuracy\n",
    "# svm_predict_dual(x_train, y_train, svm_model_dual)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.281637057117681\n"
     ]
    }
   ],
   "source": [
    "# Quick check alpha\n",
    "def quick_check_dual(model):\n",
    "    a_dual = np.sum(model)\n",
    "    print(a_dual)\n",
    "quick_check_dual(svm_model_dual)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 200)\n",
      "-0.1451352273952501 1.7798092842125055\n"
     ]
    },
    {
     "data": {
      "text/plain": "matrix([[-2.62255924e-02],\n        [-1.14172087e-01],\n        [ 4.18625306e-02],\n        [-5.22990713e-02],\n        [ 7.55230745e-02],\n        [-7.49278322e-03],\n        [ 2.79583447e-02],\n        [-1.01830347e-02],\n        [ 5.69949876e-03],\n        [ 9.35643587e-04],\n        [ 9.63096129e-02],\n        [ 6.44609832e-02],\n        [ 6.85387186e-02],\n        [ 6.24582054e-02],\n        [ 1.82642690e-02],\n        [-2.39426375e-02],\n        [-5.77822608e-02],\n        [-4.51056352e-02],\n        [-5.51932768e-02],\n        [-2.57671265e-02],\n        [-2.12456034e-03],\n        [ 4.38299699e-02],\n        [-8.61260521e-03],\n        [-4.62287667e-02],\n        [-2.00099113e-02],\n        [-1.86215919e-02],\n        [-3.54752780e-03],\n        [ 9.43200833e-03],\n        [-7.37746304e-02],\n        [ 1.15434720e-01],\n        [-2.37134176e-02],\n        [-1.37868546e-02],\n        [ 6.08666321e-02],\n        [-2.12018774e-02],\n        [ 8.70499830e-02],\n        [-3.83765354e-02],\n        [ 2.25724478e-02],\n        [-5.22947670e-02],\n        [ 5.51294068e-02],\n        [-3.70551341e-02],\n        [ 2.71672932e-02],\n        [ 2.27373099e-02],\n        [-2.35835615e-02],\n        [-4.08111071e-03],\n        [ 2.74321264e-02],\n        [-2.47141028e-02],\n        [ 1.45889595e-01],\n        [ 7.26142075e-02],\n        [ 1.54866127e-02],\n        [ 9.83964405e-02],\n        [-3.15667005e-02],\n        [ 3.83365354e-02],\n        [ 8.67143789e-02],\n        [-4.81684896e-02],\n        [ 5.38233908e-02],\n        [-4.18255604e-02],\n        [-5.71163361e-02],\n        [ 9.62863684e-02],\n        [-3.68705694e-02],\n        [ 7.26801556e-01],\n        [ 2.38017519e-02],\n        [-4.88637747e-02],\n        [ 3.43488845e-02],\n        [-1.54280698e-02],\n        [-5.54647145e-03],\n        [ 1.87180931e-02],\n        [-2.07242219e-02],\n        [-2.92814877e-02],\n        [-2.76091058e-02],\n        [-4.02809324e-02],\n        [-4.53598699e-02],\n        [-6.83864573e-02],\n        [-5.52819992e-02],\n        [ 1.12229525e-01],\n        [ 3.76847923e-02],\n        [ 6.21946413e-02],\n        [-3.59246769e-02],\n        [-5.26888723e-02],\n        [ 2.70595397e-02],\n        [ 4.23786880e-02],\n        [ 4.10292040e-02],\n        [-2.32672871e-02],\n        [-1.05080931e-02],\n        [ 2.50043056e-02],\n        [ 4.84592480e-02],\n        [-2.66989282e-02],\n        [-5.98373091e-02],\n        [ 2.84283731e-02],\n        [ 1.16710663e-02],\n        [-4.74119042e-01],\n        [-4.61131505e-03],\n        [ 5.95633441e-02],\n        [ 2.97194432e-02],\n        [-3.31037661e-02],\n        [-3.03643153e-03],\n        [-3.91363830e-02],\n        [-1.99915757e-02],\n        [-3.61217374e-02],\n        [-2.34659857e-02],\n        [-5.65407028e-02],\n        [ 2.82185211e-02],\n        [ 1.92959307e-02],\n        [-3.89495656e-02],\n        [-4.23792659e-02],\n        [-5.97275041e-03],\n        [-2.86393217e-02],\n        [ 4.74948059e-03],\n        [-5.98673598e-02],\n        [-5.68690384e-01],\n        [-8.55506133e-02],\n        [ 2.93526335e-03],\n        [ 5.52028446e-03],\n        [-2.29984730e-02],\n        [-2.59707075e-02],\n        [ 8.43270381e-02],\n        [ 6.74411972e-02],\n        [-5.43378966e-02],\n        [-6.11125714e-02],\n        [-4.38802727e-04],\n        [ 2.16109725e-04],\n        [ 6.41404068e-02],\n        [-3.95143947e-02],\n        [-4.39401435e-02],\n        [ 1.17619036e-01],\n        [-7.26745952e-02],\n        [-1.04048444e-03],\n        [ 6.69185353e-02],\n        [ 2.42862046e-02],\n        [-4.51746027e-03],\n        [ 1.72231529e-03],\n        [ 9.14168305e-02],\n        [-8.53808157e-03],\n        [-2.35050157e-02],\n        [ 2.67158081e-02],\n        [-1.78152507e-02],\n        [ 1.54492300e-02],\n        [ 3.90063286e-02],\n        [ 5.82819962e-02],\n        [ 5.99276022e-02],\n        [ 2.57005679e-03],\n        [-3.12658121e-02],\n        [-1.30840169e-01],\n        [-6.45065673e-03],\n        [ 2.18757744e-02],\n        [ 5.01755647e-03],\n        [ 1.94355269e-02],\n        [-4.89011830e-03],\n        [-1.69497278e-02],\n        [ 2.38019554e-02],\n        [-3.76255948e-02],\n        [-1.82633189e-02],\n        [-1.86938461e-02],\n        [ 4.25720278e-03],\n        [-3.30312615e-02],\n        [-3.16010150e-02],\n        [-3.94707451e-01],\n        [ 5.17800441e-02],\n        [ 8.92803291e-02],\n        [ 8.19199352e-02],\n        [-3.49821335e-02],\n        [ 4.13585918e-02],\n        [-8.60315316e-03],\n        [-3.51033947e-02],\n        [ 2.88046208e-02],\n        [-1.73425493e-02],\n        [-1.60173345e-02],\n        [ 6.04988279e-03],\n        [-6.09959225e-02],\n        [-7.53436535e-03],\n        [-6.27898299e-02],\n        [-3.24358907e-02],\n        [-4.03820825e-02],\n        [ 4.47652839e-01],\n        [ 4.73037025e-03],\n        [ 3.03166546e-03],\n        [-2.29548474e-02],\n        [ 5.98140296e-02],\n        [ 3.17240447e-02],\n        [-2.36311136e-02],\n        [-3.40280557e-03],\n        [ 1.30850990e-02],\n        [-6.25725935e-02],\n        [ 1.47522372e-02],\n        [ 6.47135587e-02],\n        [-1.09377261e-01],\n        [-7.84232751e-02],\n        [-5.58169526e-02],\n        [-1.88988407e-02],\n        [ 2.92359196e-02],\n        [ 9.53593545e-02],\n        [-1.36934101e-02],\n        [-7.56693266e-03],\n        [-1.60721987e-02],\n        [ 4.01214275e-02],\n        [ 5.52887237e-03],\n        [ 1.84784809e-02],\n        [-2.54858464e-02],\n        [ 5.34745560e-02],\n        [-5.86913811e-02],\n        [-6.68120535e-03],\n        [ 1.77980928e+00]])"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain the primal problem solution w,b from its dual solution alpha\n",
    "def obtain_primal_from_dual(data_train, label_train, model_primal, model_dual):\n",
    "    # model = model.T\n",
    "    # model = model[support_vectors]\n",
    "    # model = model.T\n",
    "    w_star = np.dot(np.matrix(model_dual), np.diag(label_train).T)\n",
    "    w_star = np.dot(w_star, data_train)\n",
    "    print(w_star.shape)\n",
    "    w_star_sum = np.sum(w_star)\n",
    "\n",
    "    xi = model_primal[data_train.shape[1]+1:]\n",
    "    support_vectors = np.where(xi < 1e-4, True, False)\n",
    "    model_dual = model_dual[support_vectors]\n",
    "    data_train = data_train[support_vectors]\n",
    "    label_train = label_train[support_vectors]\n",
    "    support_vectors = np.where(model_dual < 1e-4, False, True)\n",
    "    # model_dual = model_dual[support_vectors]\n",
    "    # print(model_dual.shape)\n",
    "    data_train = data_train[support_vectors]\n",
    "    label_train = label_train[support_vectors]\n",
    "    b_star = np.dot(w_star, data_train.T)\n",
    "    b_star = np.matrix(label_train) - b_star\n",
    "    b_star_sum = b_star.mean()\n",
    "    dual_model = np.concatenate((w_star.T,np.matrix(b_star_sum)), axis=0)\n",
    "    print(w_star_sum, b_star_sum)\n",
    "    return dual_model\n",
    "obtain_primal_from_dual(x_train, y_train, svm_model_primal, svm_model_dual)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1     2     3     4     5     6     7     8     9     10   ...   191  \\\n",
      "16    1.05 -1.79  0.90  0.68  0.54 -1.93 -0.71 -0.18  1.40  0.73  ...  1.18   \n",
      "54    0.29 -2.31 -0.40 -0.73  0.11  0.39 -0.58 -0.16  2.31  2.19  ...  0.62   \n",
      "88    1.65  0.32 -0.72  0.95  1.07  2.57  1.22  1.19  0.54  0.05  ... -1.69   \n",
      "130  -0.59  0.41  0.13  2.90  0.43 -0.27  0.66 -0.59 -1.10  0.51  ... -0.74   \n",
      "145  -0.83  1.32 -0.55  1.65  0.46  0.30  1.28  0.91  1.93  1.69  ... -0.47   \n",
      "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
      "3893 -0.44  1.15  0.95  1.38 -0.04  0.15  0.27  2.19  0.37  0.02  ...  1.13   \n",
      "3916  0.15 -0.74  1.07 -0.64 -0.74 -0.82 -0.01  0.06 -1.48 -1.37  ...  0.66   \n",
      "3942  0.33 -1.00 -0.00 -1.26  0.65  1.27  0.95 -0.44 -1.22 -0.56  ...  0.04   \n",
      "3953  0.16 -1.60  1.34  1.34 -0.10  0.22  0.99  0.81  2.00 -1.54  ...  2.20   \n",
      "3969  0.79  1.01  1.20 -0.78  1.69  1.52 -0.30 -1.12  0.15 -2.31  ... -0.39   \n",
      "\n",
      "       192   193   194   195   196   197   198   199   200  \n",
      "16    1.72  1.12  0.09 -0.40  0.69  0.32  0.39  0.60 -1.66  \n",
      "54   -0.29 -0.38 -1.66  0.17 -0.47 -0.31  0.10  0.06  0.54  \n",
      "88    0.61 -0.20 -0.15  0.74 -0.32 -1.11 -0.42 -1.27  0.91  \n",
      "130   0.96  0.09 -0.79 -0.75  0.00 -1.34 -0.28  0.15  1.64  \n",
      "145   1.69  0.64  0.97 -0.83  1.17 -0.73 -0.86  0.24 -0.06  \n",
      "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
      "3893 -1.07 -1.02  0.35 -0.18  0.89  0.24 -0.96 -0.16  0.65  \n",
      "3916  0.27  1.31  1.89  0.06  0.73 -0.78  0.51 -0.69 -0.36  \n",
      "3942 -1.07 -2.16 -0.02 -1.53 -0.64  1.11  0.94 -0.09  1.76  \n",
      "3953 -0.07 -0.46 -0.21 -0.80  0.56  0.96  0.84 -0.86 -1.25  \n",
      "3969 -1.93  0.71  1.29  0.93 -1.05 -1.02  0.85 -0.97  0.98  \n",
      "\n",
      "[179 rows x 200 columns] [ 1. -1.  1.  1. -1. -1. -1. -1.  1.  1. -1.  1.  1.  1. -1. -1.  1. -1.\n",
      "  1. -1. -1.  1.  1. -1.  1. -1. -1.  1. -1. -1.  1.  1. -1.  1. -1. -1.\n",
      " -1. -1. -1. -1.  1. -1. -1. -1.  1.  1.  1.  1.  1. -1.  1. -1. -1.  1.\n",
      "  1.  1.  1. -1. -1.  1.  1. -1. -1.  1. -1.  1.  1.  1. -1.  1. -1. -1.\n",
      " -1.  1.  1. -1. -1.  1.  1. -1.  1.  1.  1.  1. -1. -1. -1.  1.  1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1.  1.  1.  1. -1.  1.  1. -1.  1. -1. -1.  1.\n",
      " -1. -1.  1. -1. -1. -1.  1. -1.  1.  1.  1. -1.  1.  1.  1. -1. -1. -1.\n",
      "  1.  1. -1.  1. -1.  1. -1. -1. -1. -1. -1. -1. -1.  1.  1.  1.  1. -1.\n",
      " -1.  1.  1.  1. -1.  1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1. -1. -1.\n",
      "  1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1.  1. -1.  1. -1.  1.]\n"
     ]
    }
   ],
   "source": [
    "# Find the support vectors from the primal problem solutions\n",
    "def obtain_support_vectors_primal(data_train, label_train, model):\n",
    "    w_primal, b_primal, xi = model[:data_train.shape[1]], model[data_train.shape[1]], model[data_train.shape[1]+1:]\n",
    "    support_vectors = np.where(xi < 1e-4, True, False)\n",
    "\n",
    "    for i in range(len(support_vectors)):\n",
    "        if label_train[i] * (np.dot(np.matrix(w_primal), np.matrix(data_train.loc[i].values).T)  + b_primal) -1 > 1e-4:\n",
    "            support_vectors[i] = False\n",
    "    data_train = data_train[support_vectors]\n",
    "    label_train = label_train[support_vectors]\n",
    "    # print(support_vectors[support_vectors].shape)\n",
    "    print(data_train, label_train)\n",
    "obtain_support_vectors_primal(x_train, y_train, svm_model_primal)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1     2     3     4     5     6     7     8     9     10   ...   191  \\\n",
      "16    1.05 -1.79  0.90  0.68  0.54 -1.93 -0.71 -0.18  1.40  0.73  ...  1.18   \n",
      "54    0.29 -2.31 -0.40 -0.73  0.11  0.39 -0.58 -0.16  2.31  2.19  ...  0.62   \n",
      "88    1.65  0.32 -0.72  0.95  1.07  2.57  1.22  1.19  0.54  0.05  ... -1.69   \n",
      "130  -0.59  0.41  0.13  2.90  0.43 -0.27  0.66 -0.59 -1.10  0.51  ... -0.74   \n",
      "145  -0.83  1.32 -0.55  1.65  0.46  0.30  1.28  0.91  1.93  1.69  ... -0.47   \n",
      "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
      "3893 -0.44  1.15  0.95  1.38 -0.04  0.15  0.27  2.19  0.37  0.02  ...  1.13   \n",
      "3916  0.15 -0.74  1.07 -0.64 -0.74 -0.82 -0.01  0.06 -1.48 -1.37  ...  0.66   \n",
      "3942  0.33 -1.00 -0.00 -1.26  0.65  1.27  0.95 -0.44 -1.22 -0.56  ...  0.04   \n",
      "3953  0.16 -1.60  1.34  1.34 -0.10  0.22  0.99  0.81  2.00 -1.54  ...  2.20   \n",
      "3969  0.79  1.01  1.20 -0.78  1.69  1.52 -0.30 -1.12  0.15 -2.31  ... -0.39   \n",
      "\n",
      "       192   193   194   195   196   197   198   199   200  \n",
      "16    1.72  1.12  0.09 -0.40  0.69  0.32  0.39  0.60 -1.66  \n",
      "54   -0.29 -0.38 -1.66  0.17 -0.47 -0.31  0.10  0.06  0.54  \n",
      "88    0.61 -0.20 -0.15  0.74 -0.32 -1.11 -0.42 -1.27  0.91  \n",
      "130   0.96  0.09 -0.79 -0.75  0.00 -1.34 -0.28  0.15  1.64  \n",
      "145   1.69  0.64  0.97 -0.83  1.17 -0.73 -0.86  0.24 -0.06  \n",
      "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
      "3893 -1.07 -1.02  0.35 -0.18  0.89  0.24 -0.96 -0.16  0.65  \n",
      "3916  0.27  1.31  1.89  0.06  0.73 -0.78  0.51 -0.69 -0.36  \n",
      "3942 -1.07 -2.16 -0.02 -1.53 -0.64  1.11  0.94 -0.09  1.76  \n",
      "3953 -0.07 -0.46 -0.21 -0.80  0.56  0.96  0.84 -0.86 -1.25  \n",
      "3969 -1.93  0.71  1.29  0.93 -1.05 -1.02  0.85 -0.97  0.98  \n",
      "\n",
      "[179 rows x 200 columns] [ 1. -1.  1.  1. -1. -1. -1. -1.  1.  1. -1.  1.  1.  1. -1. -1.  1. -1.\n",
      "  1. -1. -1.  1.  1. -1.  1. -1. -1.  1. -1. -1.  1.  1. -1.  1. -1. -1.\n",
      " -1. -1. -1. -1.  1. -1. -1. -1.  1.  1.  1.  1.  1. -1.  1. -1. -1.  1.\n",
      "  1.  1.  1. -1. -1.  1.  1. -1. -1.  1. -1.  1.  1.  1. -1.  1. -1. -1.\n",
      " -1.  1.  1. -1. -1.  1.  1. -1.  1.  1.  1.  1. -1. -1. -1.  1.  1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1.  1.  1.  1. -1.  1.  1. -1.  1. -1. -1.  1.\n",
      " -1. -1.  1. -1. -1. -1.  1. -1.  1.  1.  1. -1.  1.  1.  1. -1. -1. -1.\n",
      "  1.  1. -1.  1. -1.  1. -1. -1. -1. -1. -1. -1. -1.  1.  1.  1.  1. -1.\n",
      " -1.  1.  1.  1. -1.  1.  1.  1. -1.  1.  1. -1.  1.  1. -1. -1. -1. -1.\n",
      "  1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1.  1.  1. -1.  1. -1.  1.]\n"
     ]
    }
   ],
   "source": [
    "# Find the support vectors from the dual problem solutions\n",
    "def obtain_support_vectors_dual(data_train, label_train, model_primal, model_dual):\n",
    "    xi = model_primal[data_train.shape[1]+1:]\n",
    "    support_vectors = np.where(xi < 1e-4, True, False)\n",
    "    model_dual = model_dual[support_vectors]\n",
    "    data_train = data_train[support_vectors]\n",
    "    label_train = label_train[support_vectors]\n",
    "    support_vectors = np.where(model_dual < 1e-4, False, True)\n",
    "    data_train = data_train[support_vectors]\n",
    "    label_train = label_train[support_vectors]\n",
    "    print(data_train, label_train)\n",
    "obtain_support_vectors_dual(x_train, y_train, svm_model_primal, svm_model_dual)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Search optimal C"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  5.1377e-02  3.7479e+02  4e+04  3e+00  3e+04\n",
      " 1:  5.3454e-02 -3.7472e+02  4e+02  3e-02  3e+02\n",
      " 2:  5.0804e-02 -6.1234e+00  6e+00  5e-04  4e+00\n",
      " 3:  1.7420e-02 -6.8341e-01  7e-01  6e-05  5e-01\n",
      " 4:  2.9628e-03 -4.7427e-02  5e-02  4e-06  3e-02\n",
      " 5:  2.6602e-03  7.5954e-04  2e-03  7e-16  1e-17\n",
      " 6:  1.3649e-03  8.3815e-04  5e-04  4e-16  3e-18\n",
      " 7:  1.0394e-03  9.2916e-04  1e-04  3e-16  2e-18\n",
      " 8:  9.6442e-04  9.5172e-04  1e-05  3e-16  3e-17\n",
      " 9:  9.5308e-04  9.5197e-04  1e-06  3e-16  8e-17\n",
      "10:  9.5290e-04  9.5196e-04  9e-07  5e-16  4e-17\n",
      "11:  9.5284e-04  9.5197e-04  9e-07  4e-16  3e-17\n",
      "12:  9.5273e-04  9.5199e-04  7e-07  4e-16  3e-17\n",
      "13:  9.5260e-04  9.5204e-04  6e-07  3e-16  2e-17\n",
      "14:  9.5248e-04  9.5208e-04  4e-07  3e-16  2e-17\n",
      "15:  9.5240e-04  9.5212e-04  3e-07  3e-16  1e-17\n",
      "16:  9.5234e-04  9.5215e-04  2e-07  3e-16  9e-18\n",
      "17:  9.5229e-04  9.5218e-04  1e-07  3e-16  1e-17\n",
      "18:  9.5226e-04  9.5219e-04  7e-08  3e-16  2e-17\n",
      "Optimal solution found.\n",
      "The training accuracy for C =  0.0009765625  is:  0.4908888888888889\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  5.1651e-02  3.7480e+02  4e+04  3e+00  3e+04\n",
      " 1:  6.0048e-02 -3.7470e+02  4e+02  3e-02  3e+02\n",
      " 2:  5.7489e-02 -6.1108e+00  6e+00  5e-04  4e+00\n",
      " 3:  2.4838e-02 -6.6482e-01  7e-01  6e-05  5e-01\n",
      " 4:  1.1238e-02 -3.8853e-02  5e-02  3e-06  3e-02\n",
      " 5:  8.6688e-03  3.0593e-03  6e-03  6e-16  1e-17\n",
      " 6:  4.3575e-03  3.4597e-03  9e-04  4e-16  5e-18\n",
      " 7:  3.8777e-03  3.7519e-03  1e-04  3e-16  6e-17\n",
      " 8:  3.7749e-03  3.7571e-03  2e-05  3e-16  3e-16\n",
      " 9:  3.7740e-03  3.7574e-03  2e-05  3e-16  2e-16\n",
      "10:  3.7729e-03  3.7578e-03  2e-05  3e-16  2e-16\n",
      "11:  3.7709e-03  3.7585e-03  1e-05  3e-16  1e-16\n",
      "12:  3.7692e-03  3.7593e-03  1e-05  3e-16  1e-16\n",
      "13:  3.7674e-03  3.7602e-03  7e-06  3e-16  1e-16\n",
      "14:  3.7660e-03  3.7609e-03  5e-06  3e-16  9e-17\n",
      "15:  3.7650e-03  3.7615e-03  3e-06  3e-16  8e-17\n",
      "16:  3.7641e-03  3.7620e-03  2e-06  3e-16  9e-17\n",
      "17:  3.7636e-03  3.7623e-03  1e-06  3e-16  5e-17\n",
      "18:  3.7633e-03  3.7626e-03  7e-07  3e-16  1e-16\n",
      "19:  3.7630e-03  3.7627e-03  3e-07  3e-16  7e-17\n",
      "20:  3.7629e-03  3.7628e-03  1e-07  3e-16  5e-17\n",
      "21:  3.7629e-03  3.7629e-03  1e-08  3e-16  2e-16\n",
      "Optimal solution found.\n",
      "The training accuracy for C =  0.00390625  is:  0.4908888888888889\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  5.2750e-02  3.7483e+02  4e+04  3e+00  3e+04\n",
      " 1:  8.6425e-02 -3.7466e+02  4e+02  3e-02  3e+02\n",
      " 2:  8.4224e-02 -6.0603e+00  6e+00  5e-04  4e+00\n",
      " 3:  5.4146e-02 -5.9120e-01  6e-01  5e-05  4e-01\n",
      " 4:  4.1283e-02 -5.0771e-03  5e-02  1e-06  1e-02\n",
      " 5:  2.0186e-02  1.1499e-02  9e-03  2e-07  2e-03\n",
      " 6:  1.4847e-02  1.4023e-02  8e-04  2e-08  1e-04\n",
      " 7:  1.4445e-02  1.4211e-02  2e-04  5e-09  4e-05\n",
      " 8:  1.4446e-02  1.4212e-02  2e-04  4e-09  4e-05\n",
      " 9:  1.4444e-02  1.4216e-02  2e-04  4e-09  3e-05\n",
      "10:  1.4437e-02  1.4222e-02  2e-04  4e-09  3e-05\n",
      "11:  1.4418e-02  1.4235e-02  2e-04  3e-09  2e-05\n",
      "12:  1.4405e-02  1.4246e-02  2e-04  2e-09  2e-05\n",
      "13:  1.4384e-02  1.4262e-02  1e-04  1e-09  1e-05\n",
      "14:  1.4367e-02  1.4274e-02  9e-05  8e-10  7e-06\n",
      "15:  1.4353e-02  1.4286e-02  7e-05  5e-10  4e-06\n",
      "16:  1.4339e-02  1.4296e-02  4e-05  3e-10  3e-06\n",
      "17:  1.4330e-02  1.4303e-02  3e-05  2e-10  1e-06\n",
      "18:  1.4324e-02  1.4308e-02  2e-05  9e-11  7e-07\n",
      "19:  1.4319e-02  1.4312e-02  6e-06  3e-11  2e-07\n",
      "20:  1.4316e-02  1.4314e-02  2e-06  7e-12  6e-08\n",
      "21:  1.4315e-02  1.4315e-02  2e-07  5e-13  4e-09\n",
      "22:  1.4315e-02  1.4315e-02  9e-09  2e-14  2e-10\n",
      "Optimal solution found.\n",
      "The training accuracy for C =  0.015625  is:  0.4908888888888889\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  5.7143e-02  3.7493e+02  4e+04  3e+00  3e+04\n",
      " 1:  1.9193e-01 -3.7446e+02  4e+02  3e-02  3e+02\n",
      " 2:  1.9104e-01 -5.8585e+00  6e+00  5e-04  4e+00\n",
      " 3:  1.6550e-01 -3.1037e-01  5e-01  3e-05  3e-01\n",
      " 4:  1.0538e-01  3.8004e-02  7e-02  6e-16  2e-16\n",
      " 5:  5.2466e-02  4.1831e-02  1e-02  4e-16  3e-17\n",
      " 6:  4.9845e-02  4.3313e-02  7e-03  3e-16  7e-17\n",
      " 7:  4.7071e-02  4.4763e-02  2e-03  3e-16  2e-16\n",
      " 8:  4.6139e-02  4.5335e-02  8e-04  3e-16  6e-17\n",
      " 9:  4.5786e-02  4.5570e-02  2e-04  3e-16  2e-16\n",
      "10:  4.5697e-02  4.5634e-02  6e-05  3e-16  8e-17\n",
      "11:  4.5664e-02  4.5660e-02  4e-06  3e-16  2e-16\n",
      "12:  4.5662e-02  4.5662e-02  2e-07  3e-16  1e-15\n",
      "13:  4.5662e-02  4.5662e-02  4e-09  3e-16  4e-15\n",
      "Optimal solution found.\n",
      "The training accuracy for C =  0.0625  is:  0.9244444444444444\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  7.4705e-02  3.7536e+02  4e+04  3e+00  3e+04\n",
      " 1:  6.1395e-01 -3.7370e+02  4e+02  3e-02  3e+02\n",
      " 2:  6.1638e-01 -5.0535e+00  6e+00  4e-04  4e+00\n",
      " 3:  5.1255e-01  5.2314e-02  5e-01  3e-06  2e-02\n",
      " 4:  1.4485e-01  8.5202e-02  6e-02  3e-07  3e-03\n",
      " 5:  1.1549e-01  1.0043e-01  2e-02  6e-08  5e-04\n",
      " 6:  1.0841e-01  1.0565e-01  3e-03  7e-09  5e-05\n",
      " 7:  1.0724e-01  1.0663e-01  6e-04  1e-09  9e-06\n",
      " 8:  1.0697e-01  1.0686e-01  1e-04  1e-10  1e-06\n",
      " 9:  1.0692e-01  1.0691e-01  1e-05  1e-11  1e-07\n",
      "10:  1.0691e-01  1.0691e-01  5e-07  5e-13  4e-09\n",
      "11:  1.0691e-01  1.0691e-01  1e-08  1e-14  1e-10\n",
      "Optimal solution found.\n",
      "The training accuracy for C =  0.25  is:  0.9622222222222222\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.4480e-01  3.7706e+02  4e+04  3e+00  3e+04\n",
      " 1:  2.3016e+00 -3.7542e+02  4e+02  3e-02  3e+02\n",
      " 2:  2.2872e+00 -6.7611e+00  9e+00  6e-04  5e+00\n",
      " 3:  1.3716e+00 -7.6474e-02  1e+00  3e-05  2e-01\n",
      " 4:  3.5991e-01  1.6808e-01  2e-01  4e-06  3e-02\n",
      " 5:  2.7298e-01  2.1470e-01  6e-02  9e-07  7e-03\n",
      " 6:  2.5140e-01  2.2952e-01  2e-02  3e-07  2e-03\n",
      " 7:  2.4288e-01  2.3539e-01  7e-03  7e-08  6e-04\n",
      " 8:  2.3952e-01  2.3778e-01  2e-03  7e-09  5e-05\n",
      " 9:  2.3870e-01  2.3845e-01  2e-04  7e-10  6e-06\n",
      "10:  2.3858e-01  2.3856e-01  2e-05  7e-11  5e-07\n",
      "11:  2.3857e-01  2.3857e-01  2e-06  4e-12  3e-08\n",
      "12:  2.3857e-01  2.3857e-01  4e-08  9e-14  8e-10\n",
      "Optimal solution found.\n",
      "The training accuracy for C =  1.0  is:  0.9717777777777777\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  4.2261e-01  3.8388e+02  4e+04  3e+00  3e+04\n",
      " 1:  9.0446e+00 -3.9031e+02  4e+02  3e-02  3e+02\n",
      " 2:  8.5538e+00 -1.8963e+01  3e+01  2e-03  1e+01\n",
      " 3:  4.3513e+00 -1.0755e+00  5e+00  2e-04  1e+00\n",
      " 4:  1.0161e+00  3.1516e-01  7e-01  2e-05  2e-01\n",
      " 5:  7.1999e-01  4.6688e-01  3e-01  6e-06  5e-02\n",
      " 6:  6.4850e-01  5.0916e-01  1e-01  3e-06  2e-02\n",
      " 7:  6.0025e-01  5.3742e-01  6e-02  1e-06  9e-03\n",
      " 8:  5.7844e-01  5.5062e-01  3e-02  4e-07  3e-03\n",
      " 9:  5.6656e-01  5.5821e-01  8e-03  7e-08  6e-04\n",
      "10:  5.6260e-01  5.6105e-01  2e-03  5e-09  4e-05\n",
      "11:  5.6183e-01  5.6170e-01  1e-04  2e-10  2e-06\n",
      "12:  5.6176e-01  5.6176e-01  3e-06  5e-12  4e-08\n",
      "13:  5.6176e-01  5.6176e-01  6e-08  9e-14  7e-10\n",
      "Optimal solution found.\n",
      "The training accuracy for C =  4.0  is:  0.9748888888888889\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  1.4931e+00  4.1116e+02  4e+04  3e+00  3e+04\n",
      " 1:  3.5891e+01 -4.5239e+02  5e+02  4e-02  3e+02\n",
      " 2:  2.9744e+01 -4.8364e+01  8e+01  5e-03  4e+01\n",
      " 3:  1.2343e+01 -3.5644e+00  2e+01  6e-04  5e+00\n",
      " 4:  3.5389e+00  5.0511e-01  3e+00  1e-04  9e-01\n",
      " 5:  2.0857e+00  1.1628e+00  9e-01  3e-05  2e-01\n",
      " 6:  1.7755e+00  1.3174e+00  5e-01  1e-05  9e-02\n",
      " 7:  1.5875e+00  1.4126e+00  2e-01  2e-06  2e-02\n",
      " 8:  1.5225e+00  1.4444e+00  8e-02  2e-07  1e-03\n",
      " 9:  1.4925e+00  1.4666e+00  3e-02  2e-08  2e-04\n",
      "10:  1.4821e+00  1.4751e+00  7e-03  4e-09  4e-05\n",
      "11:  1.4787e+00  1.4780e+00  7e-04  2e-10  1e-06\n",
      "12:  1.4783e+00  1.4783e+00  4e-05  9e-12  8e-08\n",
      "13:  1.4783e+00  1.4783e+00  1e-06  3e-13  2e-09\n",
      "Optimal solution found.\n",
      "The training accuracy for C =  16.0  is:  0.974\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  5.1224e+00  5.2042e+02  4e+04  3e+00  3e+04\n",
      " 1:  1.4132e+02 -6.9158e+02  8e+02  6e-02  5e+02\n",
      " 2:  9.4743e+01 -7.4803e+01  2e+02  8e-03  7e+01\n",
      " 3:  3.2914e+01 -1.0730e+01  4e+01  2e-03  2e+01\n",
      " 4:  1.3661e+01 -3.2280e-01  1e+01  6e-04  5e+00\n",
      " 5:  6.7993e+00  3.0825e+00  4e+00  1e-04  1e+00\n",
      " 6:  5.1367e+00  3.9250e+00  1e+00  2e-05  1e-01\n",
      " 7:  4.6913e+00  4.1598e+00  5e-01  4e-06  3e-02\n",
      " 8:  4.4907e+00  4.2760e+00  2e-01  6e-07  5e-03\n",
      " 9:  4.4113e+00  4.3272e+00  8e-02  2e-15  1e-12\n",
      "10:  4.3773e+00  4.3557e+00  2e-02  2e-15  4e-13\n",
      "11:  4.3674e+00  4.3642e+00  3e-03  2e-15  2e-12\n",
      "12:  4.3660e+00  4.3655e+00  4e-04  2e-15  2e-12\n",
      "13:  4.3657e+00  4.3657e+00  1e-05  2e-15  2e-11\n",
      "14:  4.3657e+00  4.3657e+00  4e-07  2e-15  1e-11\n",
      "Optimal solution found.\n",
      "The training accuracy for C =  64.0  is:  0.9713333333333334\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0:  9.1994e+00  9.5951e+02  4e+04  3e+00  6e+03\n",
      " 1:  5.3418e+02 -1.5165e+03  2e+03  1e-01  3e+02\n",
      " 2:  3.0213e+02 -1.6086e+02  5e+02  2e-02  4e+01\n",
      " 3:  1.1476e+02 -3.5602e+01  2e+02  6e-03  1e+01\n",
      " 4:  5.9843e+01 -7.8088e+00  7e+01  3e-03  5e+00\n",
      " 5:  3.1801e+01  6.0151e+00  3e+01  9e-04  2e+00\n",
      " 6:  2.1352e+01  1.1064e+01  1e+01  3e-04  6e-01\n",
      " 7:  1.7315e+01  1.3049e+01  4e+00  1e-04  2e-01\n",
      " 8:  1.5423e+01  1.3987e+01  1e+00  3e-05  6e-02\n",
      " 9:  1.4785e+01  1.4303e+01  5e-01  6e-06  1e-02\n",
      "10:  1.4567e+01  1.4441e+01  1e-01  1e-06  2e-03\n",
      "11:  1.4512e+01  1.4477e+01  3e-02  7e-08  1e-04\n",
      "12:  1.4496e+01  1.4491e+01  5e-03  9e-09  2e-05\n",
      "13:  1.4493e+01  1.4493e+01  2e-04  3e-10  5e-07\n",
      "14:  1.4493e+01  1.4493e+01  3e-06  5e-12  1e-08\n",
      "Optimal solution found.\n",
      "The training accuracy for C =  256.0  is:  0.966\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.4154e+02  2.7488e+03  4e+04  4e+00  2e+03\n",
      " 1:  1.7704e+03 -3.3962e+03  6e+03  4e-01  2e+02\n",
      " 2:  8.4128e+02 -3.6717e+02  1e+03  6e-02  3e+01\n",
      " 3:  3.4061e+02 -8.9688e+01  4e+02  2e-02  9e+00\n",
      " 4:  1.8579e+02 -1.3214e+01  2e+02  8e-03  4e+00\n",
      " 5:  1.1565e+02  2.1405e+01  1e+02  3e-03  2e+00\n",
      " 6:  8.5843e+01  3.6149e+01  5e+01  1e-03  7e-01\n",
      " 7:  6.4531e+01  4.7100e+01  2e+01  4e-04  2e-01\n",
      " 8:  5.7800e+01  5.0474e+01  7e+00  1e-04  5e-02\n",
      " 9:  5.5073e+01  5.1919e+01  3e+00  3e-05  1e-02\n",
      "10:  5.3938e+01  5.2548e+01  1e+00  7e-06  3e-03\n",
      "11:  5.3550e+01  5.2799e+01  8e-01  2e-06  1e-03\n",
      "12:  5.3359e+01  5.2941e+01  4e-01  1e-06  5e-04\n",
      "13:  5.3189e+01  5.3067e+01  1e-01  7e-08  3e-05\n",
      "14:  5.3136e+01  5.3112e+01  2e-02  6e-09  3e-06\n",
      "15:  5.3124e+01  5.3123e+01  8e-04  2e-10  8e-08\n",
      "16:  5.3123e+01  5.3123e+01  2e-05  3e-12  2e-09\n",
      "Optimal solution found.\n",
      "The training accuracy for C =  1024.0  is:  0.9626666666666667\n",
      "The optimal C found in the validation set is:  4.0\n"
     ]
    }
   ],
   "source": [
    "# Search optimal C in primal\n",
    "para_c = list(np.logspace(-5, 5, 11, base=4))\n",
    "optimal_c = 0\n",
    "test_accuracy = 0\n",
    "for c in para_c:\n",
    "    model_primal_c = svm_train_primal(x_train , y_train , c)\n",
    "    test_accuracy_primal = svm_predict_primal(x_valid , y_valid , model_primal_c)\n",
    "    if test_accuracy < test_accuracy_primal:\n",
    "        optimal_c = c\n",
    "        test_accuracy = test_accuracy_primal\n",
    "    print('The training accuracy for C = ', c, ' is: ', test_accuracy_primal)\n",
    "print(\"The optimal C found in the validation set is: \", optimal_c)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Search C in dual\n",
    "# para_c = list(range(1,101,5))\n",
    "# for c in para_c:\n",
    "#     model_dual_c = svm_train_dual(x_train , y_train , c)\n",
    "#     test_accuracy_dual = svm_predict_dual(x_valid , y_valid , model_dual_c)\n",
    "#     print('The training accuracy for C = ', c, ' is: ', test_accuracy_dual)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Scikit-learn SVM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy for optimal C =  4.0  is:  0.964\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# sklearn with linear SVM\n",
    "def sklearn_svm(data_train, label_train, regularisation_para_C, data_test, label_test):\n",
    "    clf = make_pipeline(StandardScaler(), LinearSVC(dual=False, tol=1e-5, C=regularisation_para_C, random_state=0))\n",
    "    clf.fit(data_train, label_train)\n",
    "    accuracy = accuracy_score(label_test, clf.predict(data_test))\n",
    "    return accuracy\n",
    "\n",
    "skl_accuracy = sklearn_svm(x_train, y_train, optimal_c, x_valid, y_valid)\n",
    "print('The training accuracy for optimal C = ', optimal_c, ' is: ', skl_accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}