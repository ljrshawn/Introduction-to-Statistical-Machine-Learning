{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def dist_vec(vec_a, vec_b):\n",
    "    return np.sqrt(np.sum(np.power((vec_a - vec_b),2)))\n",
    "\n",
    "def k_means_clustering_test(data, k):\n",
    "    m, n = data.shape\n",
    "    centroids = data.take(np.random.choice(m,k,replace=False),axis=0).reset_index(drop=True)\n",
    "    # print(centroids)\n",
    "\n",
    "    distance = []\n",
    "    for i in range(k):\n",
    "        distance.append(1)\n",
    "\n",
    "    groups = []\n",
    "\n",
    "    while sum(distance) != 0.0 :\n",
    "\n",
    "        groups = []\n",
    "        for i in range(k):\n",
    "            groups.append(pd.DataFrame(columns=list(data.columns)))\n",
    "\n",
    "        for i, r in data.iterrows():\n",
    "            p = np.matrix(r)\n",
    "            distances = [dist_vec(p, np.matrix(centroids.iloc[c,:])) for c in range(centroids.shape[0])]\n",
    "            min_dis = np.argmin(distances)\n",
    "            groups[min_dis].loc[len(groups[min_dis])] = list(p.flat)\n",
    "\n",
    "        new_centroids = pd.DataFrame(columns=list(data.columns))\n",
    "        for i, g in enumerate(groups):\n",
    "            mid = np.matrix(np.mean(g, axis=0))\n",
    "            dis = dist_vec(mid, np.matrix(centroids.iloc[i,:]))\n",
    "            if  dis < 1e-2:\n",
    "                dis = 0.0\n",
    "\n",
    "            distance[i] = dis\n",
    "            new_centroids.loc[len(new_centroids)] = list(mid.flat)\n",
    "            # print(\"length: \", len(g))\n",
    "            # print(dis)\n",
    "        centroids = new_centroids\n",
    "\n",
    "    # print(centroids)\n",
    "    return centroids, groups\n",
    "\n",
    "k_mean_result = k_means_clustering_test(x, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def k_means(data):\n",
    "    sse = []\n",
    "    for kk in range(1,15):\n",
    "        estimator = KMeans(n_clusters=kk)\n",
    "        estimator.fit(data)\n",
    "        sse.append(estimator.inertia_)\n",
    "    X = range(1,15)\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('SSE')\n",
    "    plt.plot(X,sse,'o-')\n",
    "    plt.show()\n",
    "\n",
    "k_means(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def best_k(dataset, size):\n",
    "    # Split data to train and valid\n",
    "    train, valid = dataset.iloc[:size, :], np.array(dataset.iloc[size:, :])\n",
    "    k=1\n",
    "\n",
    "    # Calculate centroids and cluster\n",
    "    result_centroids, result_cluster = k_means_clustering(train, k)\n",
    "    # Calculate loss function\n",
    "    distance_cur = loss_dis(valid, result_centroids, k)\n",
    "\n",
    "    dist_diff = [] # Distance between previous loss and current loss\n",
    "    for kk in range(2,15):\n",
    "\n",
    "        distance_bef = distance_cur\n",
    "        result_centroids, result_cluster = k_means_clustering(train, kk)\n",
    "        distance_cur = loss_dis(valid, result_centroids, kk)\n",
    "        dis = distance_bef - distance_cur\n",
    "        dist_diff.append(dis)\n",
    "        # When current loss difference is much smaller than previous, pup out previous k\n",
    "        # According to Elbow method, when the optimization effect becomes insignificant, the optimal solution appears\n",
    "        if kk > 3:\n",
    "            if 0.9 < dist_diff[-1]/dist_diff[-2] < 1:\n",
    "                k=kk-1\n",
    "                break\n",
    "            if dist_diff[-2]/dist_diff[-3] > 1:\n",
    "                if dist_diff[-1]/dist_diff[-3] > 0.9:\n",
    "                    k=kk-2\n",
    "                    print(k)\n",
    "                    break\n",
    "\n",
    "    X = range(2,kk+1)\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('dist_diff')\n",
    "    plt.plot(X,dist_diff,'o-')\n",
    "    plt.show()\n",
    "    return k\n",
    "\n",
    "best_k(x, 4000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}